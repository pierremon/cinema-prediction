---
title: "R Notebook"
output: html_notebook
---


```{r}
###############Initialisation 
rm(list=objects())
###############packages
library(dygraphs)
library(xts)
library(tidyverse)
library(car)
library(dummies)
library(gam)
dataTrain <- read_delim("/media/matthieu/disque dur Matthieu/Matthieu/Mes Documents/R/Projet M2 StatML/tmdb-box-office-prediction/train.csv", col_names =TRUE, delim=',')
#dataTest <- read_delim("//mnt/chromeos/MyFiles/Mes Documents/Projet StatML/test.csv", col_names =TRUE, delim=',')
summary(dataTrain)
```

# ##########################
# I - 3 catégories de BDDS #
# ##########################



# 1. Catégorie 1
# --------------

```{r}
DataCat1 <- subset(dataTrain, select = c("budget", "popularity", "runtime", "revenue"))
DataCat1[is.na(DataCat1)] <- 0
#DataCat2 <- subset(dataTrain, select = c("revenue"))
```




# 2. Catégorie 2
# --------------

```{r}
###############Conversion en données chiffrées
genres_matching_point <- "Comedy|Horror|Action|Drama|Documentary|Science Fiction|Crime|Fantasy|Thriller|Animation|Adventure|Mystery|War|Romance|Music|Family|Western|History|TV Movie|Foreign"    #inspiré du notebook sur internet
#dataTrain$genresName <- str_extract(dataTrain$genres, genres_matching_point)            #le pb c'est qu'on ne garde que le premier genres, parfois classé par ordre alphabétique ??
genresName <- str_extract_all(dataTrain$genres, genres_matching_point, simplify = TRUE)        #c'est pour ça que je l'ai changé en extract all, et la ca fait ce que je veux ie : une matrice qui a pour lignes chaque film (3000) donne le vecteur de tous les genres auquel il appartient
#creation d'une "dummy matrix" (une matrice avec des 1 sile film (ligne) appartient au genre (colonne), 0 sinon)
#étant donné qu'il y a 20 genres on va renvoyer une matrice avec 20 colonnes (une pour chaque genre) et 3000 lignes
dummyMatrixGenres <- matrix(0, ncol = 20, nrow = 3000)
genres_matching_point <- strsplit(genres_matching_point, "|", fixed= TRUE)
for (i in 1:length(genres_matching_point[[1]])) {
  for (j in (1:length(dataTrain$id))) {
    if (genres_matching_point[[1]][i] %in% genresName[j,]){
      dummyMatrixGenres[j,i] <- 1
    }
  }
}
#on va injecter cette dummy matrice dans notre data frame (et on met les bons noms de colonne)
GenresDataFrame <- as.data.frame(dummyMatrixGenres)
colnames(GenresDataFrame) = genres_matching_point[[1]]
DataCat2 <- data.frame(GenresDataFrame)
```

```{r}
ProductionCountry <- str_extract_all(string = dataTrain$production_countries, 
                                      pattern = "[:upper:]{2}", simplify = TRUE) #inspiré du notebook, sert surtout à avoir une colonne plus jolie
tableProductionCountry <- names(table(ProductionCountry, exclude = c("", "NA", NA)))
ncolumn = length(tableProductionCountry)
dummyMatrixProdCountry <- matrix(0, ncol = ncolumn, nrow = 3000)
for (i in 1:length(tableProductionCountry)) {
  for (j in (1:length(dataTrain$id))) {
    if (tableProductionCountry[i] %in% ProductionCountry[j,]){
      dummyMatrixProdCountry[j,i] <- 1
    }
  }
}
#on va injecter cette dummy matrice dans notre data frame (et on met les bons noms de colonne)
ProdCountryDataFrame <- as.data.frame(dummyMatrixProdCountry)
colnames(ProdCountryDataFrame) = tableProductionCountry
DataCat2 <- data.frame(DataCat2, ProdCountryDataFrame)
```

```{r}
#Dans homepages, on va mettre 1 si y'en a une, 0 si y'en a pas en gros.
dummyMatrixHomepages <- matrix(1,ncol=1,nrow=3000)
for (i in 1:3000){
  if (is.na(dataTrain$homepage[i])){
   dummyMatrixHomepages[i,1]=0 
  }
}
DataCat2 <- data.frame(DataCat2, dummyMatrixHomepages)
```

```{r}
#Une seule langue originale par film. 36 langues différentes. On crée 36 colonnes, et pour chaque ligne (i.e film), on a un 1 dans la colonne correspondant à sa langue originale.
dummyMatrixLO <- matrix(0,ncol=36,nrow=3000)
tableLO=names(table(dataTrain$original_language))
for (i in 1:36) {
  for (j in (1:3000)) {
    if (tableLO[i] %in% dataTrain$original_language[j]){
      dummyMatrixLO[j,i] <- 1
    }
  }
}
#Puis on injecte:
DataCat2 <- data.frame(DataCat2, dummyMatrixLO)
```


Il y a quelques colonnes que je ne prends pas en compte dans cat 2 :

belongs_to_collection : nom de la série dans laquelle s'inscrit le film (ex : James Bond), vide s'il n'y a rien
production_companies : (parfois vide)
release_date : date de sortie
keywords
cast : (acteurs + roles...)
crew : (réals...)


!! SI JE M'ENNUIE JE PEUX ESSAYER DE FAIRE UN TRUC POUR LES MOIS DES SORTIES DES FILMS !!

# ##########################################
# Ajoutons pour voir belongs to collection # 
# ##########################################

```{r}
###############Conversion en données chiffrées
dataTrain$collectionName <- str_extract(dataTrain$belongs_to_collection, 
                                        pattern = "(?<=name\\'\\:\\s{1}\\').+(?=\\'\\,\\s{1}\\'poster)")  #inspiré du notebook, sert surtout à avoir une colonne plus jolie
head(dataTrain$collectionName)
sum(!is.na(dataTrain$collectionName))
dim(dataTrain[1:3000,] %>%
   group_by(collectionName) %>%
   summarise(movie_count = n()) %>%
   arrange(desc(movie_count)) %>%
   filter(!is.na(collectionName)))    #ne sert qu'a voir si on a bien le bon nombre de colonnes

#creation of a dummy matrix
dummy_matrice_collection <- dummy(dataTrain$collectionName, sep=".")   #création de la matrice dummy (un colonne par collection on met 1 si le film appartient à cette collection, 0 sinon)
dim(dummy_matrice_collection)                                          #on a une matrice avec un colonne de trop
colnames(dummy_matrice_collection)[ncol(dummy_matrice_collection)]                          #la dernière colonne c'est NA
DataCat2 <- data.frame(DataCat2, dummy_matrice_collection)
```

# #########################################
# Ajoutons pour voir production companies # 
# #########################################

```{r}
ProductionCies <- str_extract_all(string = dataTrain$production_companies,
                                  pattern = '[:digit:]+', simplify = TRUE)  

#print(head(ProductionCies))
#print(ProductionCies[1,3])

tableProductionCies <- table(ProductionCies, exclude = c("", "NA", NA))
ncolumn = length(tableProductionCies)

print(ncolumn)      #il faudrait donc ajouter 3698 colonnes donc il va falloir tronquer un petit peu :)

#print(tableProductionCies[10])
print(sort(tableProductionCies, decreasing = TRUE)[1:30])

dummyMatrixProdCies <- matrix(0, ncol = ncolumn, nrow = 3000)

for (i in 1:length(tableProductionCies)) {
  for (j in (1:length(dataTrain$id))) {
    if (tableProductionCies[i] %in% ProductionCies[j,]){
      dummyMatrixProdCies[j,i] <- 1
    }
  }
}

#on va injecter cette dummy matrice dans notre data frame (et on met les bons noms de colonne)
ProdCiesDataFrame <- as.data.frame(dummyMatrixProdCies)
colnames(ProdCiesDataFrame) = tableProductionCies
DataCat2 <- data.frame(DataCat2, ProdCiesDataFrame)

#print(tableProductionCies)
```

# ##########################################
# II - Divisons en data train et data test #
# ##########################################

```{r}
TrainCat1 <- DataCat1[1:2500,]
TestCat1 <- DataCat1[2501:3000,]
```



# ##############################################################
# III - Maintenant commençons vraiment les algos : Catégorie 1 #
# ##############################################################

On dispose donc ici des variables durée, popularité et budget du film, pour prédire son revenu. On effectue pour cela des modèles additifs:

```{r}

train<-DataCat1[1:2500,]


g<-gam(revenue~s(budget)+s(popularity)+s(runtime),data = train)
summary(g) 
```
funfact: quand on regarde les degrés de liberté, c'est 8, 9 et 3.5. Donc plus linéaire en runtime qu'en budget (marrant).

```{r}
test<-DataCat1[2500:3000,]

pred<-predict(g,newdata = test)
actual=DataCat1$revenue[2500:3000]

#R au carré:
rss <- sum((pred - mean(actual)) ^ 2)
tss <- sum((actual - pred) ^ 2)
rsq <- rss/(rss+tss)
print(rsq)

rsq <- 1 - rss/tss
print(rsq)
```
On obtient en gros 0.60-0.65 pour le R-carré. 

Ensuite qqs plots:

prédictions et vraies valeurs en fonction du budget:
```{r}

Budget<-test$budget
Revenue<-actual
y2<-pred
plot(Budget,Revenue,type="p")
points(Budget,y2,col=2)
legend("topleft", legend=c("Training values", "Testing values"),
       col=c("black", "red"), lty=1:2, cex=0.8, pch=c("o","o"))
```
en fonction de la popularité:
```{r}

popu<-test$popularity
Revenue<-actual
y2<-pred
plot(popu,Revenue,type="p")
points(popu,y2,col=2)
legend("topleft", legend=c("Training values", "Testing values"),
       col=c("black", "red"), lty=1:2, cex=0.8, pch=c("o","o"))
```
C'est un petit peu mions joli qu'en fonction du budget (a l'air moins linéaire quoi)

prédictions en fonction des vraies valeurs, c'est pas une ligne droite, mais ça a un peu de gueule je trouve:
```{r}
plot(actual,pred)
```




# ###############################################
# IV - Maintenant commençons vraiment les algos #
# ###############################################

```{r}
prediction_DataCat1<-predict(g,newdata = DataCat1)
DataCat2$ecart <- DataCat1$revenue - prediction_DataCat1


TrainCat2 <- DataCat2[1:2500,]
TestCat2 <- DataCat2[2501:3000,]
```

# 1. XGBoost
# ----------

Commençons par appeler les bibliothèques
```{r}
library(xgboost)
library(caret)    #sert à tester differents paramètres pour le xgboost, il suffit de le lancer une fois et de noter les bons paramètres
```


Maintenant il s'agit de mettre la BDD dans le bon format.

```{r}
#on enlève revenue des BDDs
X_trainXGB = xgb.DMatrix(as.matrix(TrainCat2 %>% select(-ecart)))
y_train = TrainCat2$ecart
X_testXGB = xgb.DMatrix(as.matrix(TestCat2 %>% select(-ecart)))
y_test = TestCat2$ecart
```

```{r}
xgb_trcontrol = trainControl(method = "boot", number = 5, allowParallel = TRUE, 
    verboseIter = FALSE, returnData = FALSE)

# j'ai mis les lignes de code en dessous en commentaires pour ne pas à avoir à les relancer : test de plusieurs paramètres

#xgbGrid <- expand.grid(nrounds = c(100,200),  
#                       max_depth = c(3, 5, 10, 15, 20),
#                       colsample_bytree = seq(0.5, 0.9, length.out = 5),
#                       ## valeurs par défaut : 
#                       eta = 0.1,
#                       gamma=0,
#                       min_child_weight = 1,
#                       subsample = 1
#                      )

# voila les bonnes valeurs dans notre cas :

xgbGrid <- expand.grid(nrounds = 100,  
                       max_depth = 5,
                       colsample_bytree = 0.5,
                       ## valeurs par défaut : 
                       eta = 0.1,
                       gamma=0,
                       min_child_weight = 1,
                       subsample = 1
                      )

set.seed(0)   #est-ce vraiment utile ??
xgb_model = train(X_trainXGB, y_train, trControl = xgb_trcontrol, tuneGrid = xgbGrid, 
    method = "xgbTree")

print(xgb_model)
```


Regardons les résultats :
```{r}
predicted = predict(xgb_model, X_testXGB)
residuals = y_test - predicted
RMSE = sqrt(mean(residuals^2))

y_test_mean = mean(y_test)
tss = sum((y_test - y_test_mean)^2)
rss = sum(residuals^2)
rsq = 1 - (rss/tss)

print(RMSE)
print(rsq)
```




Regardons juste pour voir les valeurs prédites en fonction des valeurs théoriques...
```{r}
plot(y_test,predicted)
```

 Bon ! je sais pas trop quoi en dire donc je vais regarder les revenues prédits
 
```{r}
Revenue<-test$revenue
print(length(Revenue))
print(length(pred))
plot(Revenue, pred,type="p")
y2 <- pred + predicted
points(Revenue,y2,col=2)
legend("topleft", legend=c("Predicted Cat1", "Predicted Cat1 and 2"),
       col=c("black", "red"), lty=1:2, cex=0.8, pch=c("o","o"))
```

C'est pas flagrant que l'on gagne !



# 2. Random Forest
# ----------------


!!! ATTENTION LA PARTIE JUSTE EN DESSOUS EST ASSEZ LONGUE UNE DEMI HEURE ENVIRON SUR MON ORDI !!!
NE LA LANCEZ PAS A CHAQUE FOIS

```{r}
library(randomForest)

X_train = as.matrix(TrainCat2 %>% select(-ecart))
X_test = as.matrix(TestCat2 %>% select(-ecart))

fit <- randomForest(y_train ~ ., data = X_train, ntree = 500,
importance=TRUE, na.action=na.omit)
print(fit)
```

```{r}
predictionRF <- predict(fit, X_test)
residuals = y_test - predictionRF
RMSE = sqrt(mean(residuals^2))

y_test_mean = mean(y_test)
tss = sum((y_test - y_test_mean)^2)
rss = sum(residuals^2)
rsq = 1 - (rss/tss)

print(RMSE)
print(rsq)
```

```{r}
plot(y_test,predictionRF)
```

 Bon ! je sais pas trop quoi en dire donc je vais regarder les revenues prédits
 
```{r}
Revenue<-test$revenue
print(length(Revenue))
print(length(pred))
plot(Revenue, pred,type="p")
y1 <- pred + predicted
points(Revenue,y1,col=2)
y2 <- pred + predictionRF
points(Revenue,y2,col=3)
legend("topleft", legend=c("Predicted Cat1", "Predicted Cat1 and 2", "Predicted Cat1 and 2 RF"),
       col=c("black", "red", "green"), lty=1:2, cex=0.8, pch=c("o","o", "o"))
```


# ################################################
# V - Les algos : Catégorie 3 #
# ################################################

On dispose de tout sauf les 2 autres catégories, et on veut prédire l'erreur comise à la suite du traitement des 2 précédentes catégories.
Appelons Error3 cette erreur à prédire. 

```{r}
Error3<-
```
On va faire sélection de variables grâce au Lasso, puis appliquer les algos de la catégorie 2 (forêts et gradient boosting).

```{r}
train<-DataCat3[0:2500,]
test<-DataCat3[2501:3000,]

x_train=as.matrix(train[0:2500,][1000:89375])
y_train=as.matrix(Error3[0:2500])
```

```{r}
lasso_model_cv=cv.glmnet(x_train,y_train,alpha=1)
plot(lasso_model_cv)
```
Ce dernier plot montre la RMSE et le nombre de variables sélectionnées en fonction du lambda (pas mal comme plot).
En général le meilleur lambda sélectionne dans les 600 variables parmi 89k, et vaut dans les 10^4. On le sélectionne:

```{r}
numero_du_best_model=which(lasso_model_cv$lambda==lasso_model_cv$lambda.min)
Lasso=lasso_model_cv$glmnet.fit$beta[,numero_du_best_model]
print (log(numero_du_best_model))
```

Sélection des variables: il ne nous reste plus qu'à retraiter les données:
```{r}
newlasso=c()
varsel=c() #listes vides à remplir, newlasso n'aura que les variables sélectionnées, et varsel coderal ces variables sélectionnées
n=0 #sera le nb de variables sélectionnées

for (i in Lasso) {
  if(i==0.) {   #si la variable n'est pas sélectionnée, on met 0 dans varsel
    varsel <- append(varsel,c(0))
  }
  
  else{ #si variable sélectionnée, on met 1 dans varsel
    newlasso <- append(newlasso,c(i))
    varsel<-append(varsel,c(1))
    n<-n+1
  }
}
print(n) #le nb de variables sélectionnées
```{r}

Maintenant on crée les données avec que les variables "importantes":
```{r}
k=1
var=as.list(Lasso)
for (i in varsel) {
  if(i==0){
    var<-var[-k]  #en gros on supprime de Lasso les variables non sélectionnées.
    k<-k-1
  }
  k<-k+1
  
}

x<-DataCat3
x2<-subset(x, select = c(names(var))) #on a pris toutes les variables (pour les 3000 films) sélectionnées
```


Puis juste faire le travail de 2 avec x2 pour prédire Error3.




